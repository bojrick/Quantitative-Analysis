{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "import numpy as numpy\n",
    "import statsmodels.api as sm\n",
    "\n",
    "apikey = 'b86e0fbbe269c65e07c6d914b958c2a1'\n",
    "apikey1= '4236aeb9edb3d547b97701ace0027d75'\n",
    "apikey2 = '2bc4371fafb796c9de834fe620ec9915'\n",
    "apikey3 = '42d1b9e43ea2ee4d4e5b4aa1952bc523'\n",
    "\n",
    "def get_data(tick,apikey):\n",
    "    ratios = pd.read_csv('https://fmpcloud.io/api/v3/ratios/'+tick+'?datatype=csv&period=quarter&&apikey='+apikey)\n",
    "    #growth = pd.read_csv('https://fmpcloud.io/api/v3/financial-growth/'+tick+'?datatype=csv&period=quarter&apikey=b86e0fbbe269c65e07c6d914b958c2a1')\n",
    "    mark_cap = pd.read_csv('https://fmpcloud.io/api/v3/historical-market-capitalization/'+tick+'?datatype=csv&period=quarter&apikey=b86e0fbbe269c65e07c6d914b958c2a1')\n",
    "    balance = pd.read_csv('https://fmpcloud.io/api/v3/balance-sheet-statement/'+tick+'?datatype=csv&period=quarter&apikey=b86e0fbbe269c65e07c6d914b958c2a1')\n",
    "    #balance_growth = pd.read_csv('https://fmpcloud.io/api/v3/balance-sheet-statement-growth/'+tick+'?datatype=csv&period=quarter&apikey=b86e0fbbe269c65e07c6d914b958c2a1')\n",
    "    income = pd.read_csv('https://fmpcloud.io/api/v3/income-statement/'+tick+'?datatype=csv&period=quarter&apikey=b86e0fbbe269c65e07c6d914b958c2a1')\n",
    "    #income_growth = pd.read_csv('https://fmpcloud.io/api/v3/income-statement-growth/'+tick+'?datatype=csv&period=quarter&apikey=b86e0fbbe269c65e07c6d914b958c2a1')\n",
    "    cash_flow = pd.read_csv('https://fmpcloud.io/api/v3/cash-flow-statement/'+tick+'?datatype=csv&period=quarter&apikey=b86e0fbbe269c65e07c6d914b958c2a1')\n",
    "    #cash_flow_growth = pd.read_csv('https://fmpcloud.io/api/v3/cash-flow-statement-growth/'+tick+'?datatype=csv&period=quarter&limit=140&apikey=b86e0fbbe269c65e07c6d914b958c2a1')\n",
    "    key_metrics = pd.read_csv('https://fmpcloud.io/api/v3/key-metrics/'+tick+'?datatype=csv&period=quarter&apikey='+apikey)\n",
    "    enterprise_values = pd.read_csv('https://fmpcloud.io/api/v3/enterprise-values/'+tick+'?datatype=csv&period=quarter&apikey='+apikey)\n",
    "    #daily_prices = pd.read_csv('https://fmpcloud.io/api/v3/historical-price-full/'+tick+'?datatype=csv&apikey=b86e0fbbe269c65e07c6d914b958c2a1')\n",
    "    table_dict = {\n",
    "         'Ratios':ratios,\n",
    "         #'Financial Growths':growth,\n",
    "         'Key metrics':key_metrics,\n",
    "         'Daily market_cap':mark_cap,\n",
    "         'Balance Sheet':balance,\n",
    "         'Income Statement':income,\n",
    "         'Cash Flow Statement':cash_flow,\n",
    "         'Enterprise Value':enterprise_values,\n",
    "         #'daily prices':daily_prices\n",
    "        }        \n",
    "    \n",
    "    return table_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from functools import reduce\n",
    "\n",
    "def get_stats(tick,key):\n",
    "    balance = pd.read_csv('https://fmpcloud.io/api/v3/balance-sheet-statement/'+tick+'?datatype=csv&period=quarter&apikey='+key)\n",
    "    income = pd.read_csv('https://fmpcloud.io/api/v3/income-statement/'+tick+'?datatype=csv&period=quarter&apikey='+key,error_bad_lines=False)\n",
    "    cash_flow = pd.read_csv('https://fmpcloud.io/api/v3/cash-flow-statement/'+tick+'?datatype=csv&period=quarter&apikey='+key)\n",
    "    enterprise_values = pd.read_csv('https://fmpcloud.io/api/v3/enterprise-values/'+tick+'?datatype=csv&period=quarter&apikey='+apikey)#parse_dates=['date'])\n",
    "    return [balance,income,cash_flow,enterprise_values]\n",
    "\n",
    "#bs = pd.read_csv('bs.csv',skiprows=1).dropna()\n",
    "#cf = pd.read_csv('CF.csv',skiprows=1,skipfooter=1).dropna()\n",
    "#Is = pd.read_csv('IS.csv',skiprows=1,skipfooter=1).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_df(df):\n",
    "    cdf = df.drop(df.columns[0],axis=1)\n",
    "    cdf = cdf.dropna()\n",
    "    cdf = cdf.transpose().reset_index()\n",
    "    cdf.columns = cdf.loc[0,:]\n",
    "    cdf = cdf.drop(0,axis=0)\n",
    "    cdf = cdf.rename(columns={cdf.columns[0]:'date'})\n",
    "    cdf['date'] = pd.to_datetime(cdf['date'].apply(lambda x:x[:-3]))#.dt.to_period('M')\n",
    "    return cdf\n",
    "\n",
    "def merge_df(list_df):\n",
    "    dfs = [prep_df(list_df[i]) for i in range(3)]\n",
    "    dfNew = reduce(lambda left,right:pd.merge(left,right,on='date',suffixes=('', '_y')),dfs)\n",
    "    dfNew = dfNew.drop(dfNew.filter(regex='_y$').columns.tolist(),axis=1)\n",
    "    return dfNew"
   ]
  },
  {
   "source": [
    "On average, large-cap corporations—those with market capitalizations of US\\$10 billion and greater—tend to grow more slowly than mid-cap companies. Mid-cap companies are those with capitalization between \\$2 and \\$10 billion, while small-cap corporations have between \\$300 million and \\$2 billion."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_comps = ['JNJ', 'PFE', 'MRK', 'AMGN', 'BMY', 'LLY', 'GILD', 'BIIB', 'BHC','MYL', 'ALXN', 'VRTX', 'PRGO', 'IDXX']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "JNJ Done..!!\n",
      "PFE Done..!!\n",
      "MRK Done..!!\n",
      "AMGN Done..!!\n",
      "BMY Done..!!\n",
      "LLY Done..!!\n",
      "GILD Done..!!\n",
      "BIIB Done..!!\n",
      "BHC Done..!!\n",
      "b'Skipping line 6: expected 26 fields, saw 102\\nSkipping line 7: expected 26 fields, saw 102\\nSkipping line 15: expected 26 fields, saw 102\\nSkipping line 16: expected 26 fields, saw 102\\nSkipping line 20: expected 26 fields, saw 102\\nSkipping line 21: expected 26 fields, saw 102\\nSkipping line 30: expected 26 fields, saw 102\\nSkipping line 31: expected 26 fields, saw 102\\n'\n",
      "MYL Done..!!\n",
      "ALXN Done..!!\n",
      "VRTX Done..!!\n",
      "PRGO Done..!!\n",
      "IDXX Done..!!\n"
     ]
    }
   ],
   "source": [
    "data_dict = {}\n",
    "for tick in selected_comps:\n",
    "    data_dict[tick] = get_stats(tick,apikey3) \n",
    "    print(tick+' Done..!!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "raw_data = []\n",
    "for tick,data2 in data_dict.items():\n",
    "    merged = merge_df(data2)\n",
    "    merged.insert(0,'Ticker',tick)\n",
    "    #merged[merged['date']>='1995-12-31']\n",
    "    raw_data.append(merged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = pd.concat(raw_data)\n",
    "#raw_data = raw_data[raw_data['date']>='1995-12-31']"
   ]
  },
  {
   "source": [
    "\n",
    "\n",
    "'CFO2TA' = fs['netCashProvidedByOperatingActivites']/fs['totalAssets']\n",
    "\n",
    "\n",
    "\n",
    "'ACC' = (fs['netIncome']-fs['netCashProvidedByOperatingActivites'])/fs['totalAssets']\n",
    "\n",
    "'CFOg' = fs['netCashProvidedByOperatingActivites']/fs['netCashProvidedByOperatingActivites'].shift(-1)+\n",
    "        fs['netCashProvidedByOperatingActivites']/fs['netCashProvidedByOperatingActivites'].shift(-4)+\n",
    "        fs['netCashProvidedByOperatingActivites']/fs['netCashProvidedByOperatingActivites'].shift(-8)\n",
    "\n",
    "'B/P' = (fs['totalAssets']-fs['totalLiabilities'])/fs['weightedAverageShsOutDil']\n",
    "\n",
    "'CAPX2TA' = fs['capitalExpenditure']/fs['totalAssets']\n",
    "\n",
    "'CAPXg' = fs['capitalExpenditure']-fs['capitalExpenditure'].shift(-1)\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs = raw_data[['date','Ticker','netIncome','totalStockholdersEquity','EPSDiluted']]\n",
    "for col in fs.columns[2:]:\n",
    "    fs[col] = fs[col].astype(float)\n",
    "#fs = fs.sort_values(by='date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "fs['se'] = (fs['totalStockholdersEquity']+fs['totalStockholdersEquity'].shift(-1)+fs['totalStockholdersEquity'].shift(-2)+fs['totalStockholdersEquity'].shift(-3))/4\n",
    "\n",
    "fs['ROE'] = (fs['netIncome']+fs['netIncome'].shift(-1)+fs['netIncome'].shift(-2)+fs['netIncome'].shift(-3))/fs['se']\n",
    "\n",
    "\n",
    "fs['EPSg'] = fs['EPSDiluted']/fs['EPSDiluted'].shift(-1) + fs['EPSDiluted']/fs['EPSDiluted'].shift(-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_ = fs[fs['date']>='1995-12'][['date','Ticker','ROE','EPSg']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "date      datetime64[ns]\n",
       "Ticker            object\n",
       "ROE              float64\n",
       "EPSg             float64\n",
       "dtype: object"
      ]
     },
     "metadata": {},
     "execution_count": 400
    }
   ],
   "source": [
    "raw_.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_['date'] = pd.to_datetime(raw_['date']).dt.to_period('Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_.index = raw_['date'].astype(str)+'-'+raw_['Ticker']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "           date Ticker       ROE      EPSg\n",
       "2020-JNJ   2020    JNJ  0.273729  3.003338\n",
       "2020-JNJ   2020    JNJ  0.251040  1.279949\n",
       "2020-JNJ   2020    JNJ  0.286386  3.008511\n",
       "2019-JNJ   2019    JNJ  0.254721  3.629328\n",
       "2019-JNJ   2019    JNJ  0.238130  0.770499\n",
       "...         ...    ...       ...       ...\n",
       "1996-IDXX  1996   IDXX  0.107275  2.330729\n",
       "1996-IDXX  1996   IDXX  0.104108  2.473123\n",
       "1996-IDXX  1996   IDXX  0.096352  2.522714\n",
       "1996-IDXX  1996   IDXX  0.102661  2.484984\n",
       "1995-IDXX  1995   IDXX  0.111531  2.566435\n",
       "\n",
       "[1321 rows x 4 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>date</th>\n      <th>Ticker</th>\n      <th>ROE</th>\n      <th>EPSg</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2020-JNJ</th>\n      <td>2020</td>\n      <td>JNJ</td>\n      <td>0.273729</td>\n      <td>3.003338</td>\n    </tr>\n    <tr>\n      <th>2020-JNJ</th>\n      <td>2020</td>\n      <td>JNJ</td>\n      <td>0.251040</td>\n      <td>1.279949</td>\n    </tr>\n    <tr>\n      <th>2020-JNJ</th>\n      <td>2020</td>\n      <td>JNJ</td>\n      <td>0.286386</td>\n      <td>3.008511</td>\n    </tr>\n    <tr>\n      <th>2019-JNJ</th>\n      <td>2019</td>\n      <td>JNJ</td>\n      <td>0.254721</td>\n      <td>3.629328</td>\n    </tr>\n    <tr>\n      <th>2019-JNJ</th>\n      <td>2019</td>\n      <td>JNJ</td>\n      <td>0.238130</td>\n      <td>0.770499</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1996-IDXX</th>\n      <td>1996</td>\n      <td>IDXX</td>\n      <td>0.107275</td>\n      <td>2.330729</td>\n    </tr>\n    <tr>\n      <th>1996-IDXX</th>\n      <td>1996</td>\n      <td>IDXX</td>\n      <td>0.104108</td>\n      <td>2.473123</td>\n    </tr>\n    <tr>\n      <th>1996-IDXX</th>\n      <td>1996</td>\n      <td>IDXX</td>\n      <td>0.096352</td>\n      <td>2.522714</td>\n    </tr>\n    <tr>\n      <th>1996-IDXX</th>\n      <td>1996</td>\n      <td>IDXX</td>\n      <td>0.102661</td>\n      <td>2.484984</td>\n    </tr>\n    <tr>\n      <th>1995-IDXX</th>\n      <td>1995</td>\n      <td>IDXX</td>\n      <td>0.111531</td>\n      <td>2.566435</td>\n    </tr>\n  </tbody>\n</table>\n<p>1321 rows × 4 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 428
    }
   ],
   "source": [
    "raw_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "metadata": {},
   "outputs": [],
   "source": [
    "prev_data = pd.read_csv('clean_data.csv')\n",
    "clean_data = prev_data.drop(prev_data.columns[0],axis=1)\n",
    "clean_data.columns = clean_data.loc[0,:]\n",
    "clean_data = clean_data.drop(0,axis=0)\n",
    "#clean_data = clean_data.drop(['RoE','EPSg'],axis=1)\n",
    "#clean_data['date'] = pd.to_datetime(clean_data['date']).dt.to_period('Y')\n",
    "#clean_data.index = clean_data['date'].astype(str)+'-'+clean_data['Ticker']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculates Forward Return given Price table from Yahoo Finance\n",
    "def forward_ret(price_df,interval):\n",
    "        returns = price_df.dropna().sort_index(ascending=False)['Adj Close'].pct_change(periods = interval)\n",
    "    #returns = returns[~(returns == 0)]\n",
    "        return returns\n",
    "\n",
    "#Returns Table of signals from Each Theme\n",
    "def get_themes_data(tick,ratios_data,price_df,data_since=None):\n",
    "    selected_ratios = ['date','returnOnEquity','operatingCashFlowPerShare','returnOnAssets','numberOfShares','earningsYield',\n",
    "    'netIncomePerShare','pbRatio','peRatio','priceToOperatingCashFlowsRatio','debtToAssets','capexPerShare','stockPrice','enterpriseValueOverEBITDA']\n",
    "\n",
    "    combined_ratios = pd.concat([ratios_data['Key metrics'], ratios_data['Ratios'],ratios_data['Enterprise Value']],axis=1)\n",
    "    combined_ratios = combined_ratios.loc[:,~combined_ratios.columns.duplicated()]\n",
    "    clean_df = combined_ratios[selected_ratios]\n",
    "    clean_df.insert(1,'Ticker',tick)\n",
    "    #print(clean_df.dtypes)\n",
    "    dates = clean_df[['date','Ticker']]\n",
    "    dates['date'] = pd.to_datetime(dates['date']).dt.to_period('M')\n",
    "    #print(dates.dropna())\n",
    "\n",
    "    #Profitibilty Theme\n",
    "    profitability = {'RoE':clean_df['returnOnEquity'],\n",
    "                                'CFO2A':(clean_df['operatingCashFlowPerShare']*clean_df['returnOnAssets'])/clean_df['netIncomePerShare'],\n",
    "                                'EPSg':clean_df['earningsYield']*clean_df['stockPrice'],\n",
    "                                'EBITDA/EV':1/(clean_df['enterpriseValueOverEBITDA'])}\n",
    "\n",
    "    profitability['EPSg'] = (profitability['EPSg']/profitability['EPSg'].shift(-1))+(profitability['EPSg']/profitability['EPSg'].shift(-4))\n",
    "\n",
    "    #Earnings Quality Theme\n",
    "    earnings_quality = {'Accruals':clean_df['returnOnAssets']-profitability['CFO2A'],\n",
    "                                            'CFOg':clean_df['operatingCashFlowPerShare']*clean_df['numberOfShares']}\n",
    "    earnings_quality['CFOg'] = earnings_quality['CFOg']/earnings_quality['CFOg'].shift(-1)+earnings_quality['CFOg']/earnings_quality['CFOg'].shift(-4)+earnings_quality['CFOg']/earnings_quality['CFOg'].shift(-8)\n",
    "\n",
    "    #Value Theme\n",
    "    value = {'B/P':1/clean_df['pbRatio'],\n",
    "                                    'E/P':1/clean_df['peRatio'],\n",
    "                                    'CFO/P':1/clean_df['priceToOperatingCashFlowsRatio']}\n",
    "\n",
    "    #Management Quality Theme\n",
    "    management_capability = {'exFINg':clean_df['debtToAssets'],\n",
    "                            'CapXg':(clean_df['capexPerShare']*clean_df['returnOnAssets'])/clean_df['netIncomePerShare']}\n",
    "    management_capability['exFINg'] = management_capability['exFINg']/management_capability['exFINg'].shift(-1)\n",
    "    management_capability['CapXg'] = management_capability['CapXg']/management_capability['CapXg'].shift(-1)\n",
    "\n",
    "    #Momentum Theme\n",
    "    momentum = {'P3m':clean_df['stockPrice']/clean_df['stockPrice'].shift(-1),\n",
    "                                        'P6m':clean_df['stockPrice']/clean_df['stockPrice'].shift(-2),\n",
    "                                        'P9m':clean_df['stockPrice']/clean_df['stockPrice'].shift(-3),\n",
    "                                        'P12m':clean_df['stockPrice']/clean_df['stockPrice'].shift(-4)}\n",
    "    \n",
    "    forwards = {}\n",
    "    ls =[1,3,6,9,12]\n",
    "    for interval in ls:\n",
    "        name = str(interval)+'m'\n",
    "        forwards[name] = forward_ret(price_df,interval)\n",
    "\n",
    "    forwards_returns = pd.DataFrame.from_dict(forwards).reset_index()\n",
    "    forwards_returns['Date'] = pd.to_datetime(forwards_returns['Date']).dt.to_period('M')\n",
    "    fr = forwards_returns.set_index('Date')\n",
    "\n",
    "    df3 = fr.loc[dates.dropna().set_index('date').index,:]\n",
    "    df3 = df3[~df3.index.duplicated(keep='first')]\n",
    "    \n",
    "    theme_dict = {'Company':dates,\n",
    "                'Profitability':profitability,\n",
    "                'Earnings Quality':earnings_quality,\n",
    "                'Value':value,\n",
    "                'Management Capability':management_capability,\n",
    "                'Momentum':momentum,\n",
    "                'Forward Returns':df3.reset_index(drop=True)}\n",
    "\n",
    "    reform = {(outerKey, innerKey): values for outerKey, innerDict in theme_dict.items() for innerKey, values in innerDict.items()}\n",
    "    reform = pd.DataFrame(reform)\n",
    "    #print(reform[('Company','date')])\n",
    "    if data_since!=None:\n",
    "    #print(reform[reform[('Company','date')]==data_since].index)\n",
    "        idx = reform[reform[('Company','date')]==data_since].index.values[0]\n",
    "    #print(idx)\n",
    "        reform = reform.iloc[:idx,:]\n",
    "\n",
    "    return reform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "metadata": {},
   "outputs": [],
   "source": [
    "def final_table(tick,apikey,Filename = None,data_since = None):\n",
    "    prices = yf.download(tick,interval=\"1mo\")\n",
    "    ratios = get_data(tick,apikey)\n",
    "\n",
    "    return get_themes_data(tick,ratios,prices,data_since = data_since)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    }
   ],
   "source": [
    "df = final_table('AAPL',apikey1)\n",
    "cols = df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    }
   ],
   "source": [
    "yf.download('AAPL',interval=\"1mo\").to_csv('aapl_1mo.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 530,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data_file_570_project.csv',names=cols,skiprows=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 531,
   "metadata": {},
   "outputs": [],
   "source": [
    "non = ['TEVA','QGEN','UTHR','BMRN']\n",
    "df = df[~df[('Company','Ticker')].isin(non)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 532,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[('Company','date')] = pd.to_datetime(df[('Company','date')]).dt.to_period('M')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 533,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df[('Company','date')].dt.year>=1996.0]#.dropna().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 534,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "  Profitability                               Earnings Quality            \\\n",
       "            RoE     CFO2A      EPSg EBITDA/EV         Accruals      CFOg   \n",
       "0      0.072202  0.072202  0.288809  0.072202         0.072202  0.866426   \n",
       "\n",
       "      Value                     Management Capability            Momentum  \\\n",
       "        B/P       E/P     CFO/P                exFINg     CapXg       P3m   \n",
       "0  0.072202  0.072202  0.072202              0.072202  0.433213  0.072202   \n",
       "\n",
       "                                Forward Returns                           \\\n",
       "        P6m       P9m      P12m              1m   3m        6m        9m   \n",
       "0  0.144404  0.216606  0.288809             0.0  0.0  0.938628  1.949458   \n",
       "\n",
       "             \n",
       "        12m  \n",
       "0  2.960289  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead tr th {\n        text-align: left;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr>\n      <th></th>\n      <th colspan=\"4\" halign=\"left\">Profitability</th>\n      <th colspan=\"2\" halign=\"left\">Earnings Quality</th>\n      <th colspan=\"3\" halign=\"left\">Value</th>\n      <th colspan=\"2\" halign=\"left\">Management Capability</th>\n      <th colspan=\"4\" halign=\"left\">Momentum</th>\n      <th colspan=\"5\" halign=\"left\">Forward Returns</th>\n    </tr>\n    <tr>\n      <th></th>\n      <th>RoE</th>\n      <th>CFO2A</th>\n      <th>EPSg</th>\n      <th>EBITDA/EV</th>\n      <th>Accruals</th>\n      <th>CFOg</th>\n      <th>B/P</th>\n      <th>E/P</th>\n      <th>CFO/P</th>\n      <th>exFINg</th>\n      <th>CapXg</th>\n      <th>P3m</th>\n      <th>P6m</th>\n      <th>P9m</th>\n      <th>P12m</th>\n      <th>1m</th>\n      <th>3m</th>\n      <th>6m</th>\n      <th>9m</th>\n      <th>12m</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.072202</td>\n      <td>0.072202</td>\n      <td>0.288809</td>\n      <td>0.072202</td>\n      <td>0.072202</td>\n      <td>0.866426</td>\n      <td>0.072202</td>\n      <td>0.072202</td>\n      <td>0.072202</td>\n      <td>0.072202</td>\n      <td>0.433213</td>\n      <td>0.072202</td>\n      <td>0.144404</td>\n      <td>0.216606</td>\n      <td>0.288809</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.938628</td>\n      <td>1.949458</td>\n      <td>2.960289</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 534
    }
   ],
   "source": [
    "df = df.replace([np.inf, -np.inf], np.nan)\n",
    "pd.DataFrame(df.isna().sum()/df.shape[0]*100).transpose().drop('Company',axis=1)#.to_csv('nasum.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 535,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 536,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: 'outliersum.csv'",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-536-dcabb8b68e5e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mQ3\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mquantile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0.75\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mIQR\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mQ3\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mQ1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mQ1\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m1.5\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mIQR\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m|\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mQ3\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1.5\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mIQR\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'outliersum.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Miniconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mto_csv\u001b[1;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, line_terminator, chunksize, date_format, doublequote, escapechar, decimal, errors)\u001b[0m\n\u001b[0;32m   3168\u001b[0m             \u001b[0mdecimal\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdecimal\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3169\u001b[0m         )\n\u001b[1;32m-> 3170\u001b[1;33m         \u001b[0mformatter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3171\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3172\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mpath_or_buf\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Miniconda3\\lib\\site-packages\\pandas\\io\\formats\\csvs.py\u001b[0m in \u001b[0;36msave\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    183\u001b[0m             \u001b[0mclose\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    184\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 185\u001b[1;33m             f, handles = get_handle(\n\u001b[0m\u001b[0;32m    186\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath_or_buf\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    187\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Miniconda3\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors)\u001b[0m\n\u001b[0;32m    491\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    492\u001b[0m             \u001b[1;31m# Encoding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 493\u001b[1;33m             \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath_or_buf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnewline\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    494\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mis_text\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    495\u001b[0m             \u001b[1;31m# No explicit encoding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mPermissionError\u001b[0m: [Errno 13] Permission denied: 'outliersum.csv'"
     ]
    }
   ],
   "source": [
    "Q1 = df[df.columns[2:]].quantile(0.25)\n",
    "Q3 = df[df.columns[2:]].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "pd.DataFrame(((df[df.columns[2:]] < (Q1 - 1.5 * IQR)) | (df[df.columns[2:]] > (Q3 + 1.5 * IQR))).sum()/df.shape[0]*100).transpose().to_csv('outliersum.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 546,
   "metadata": {},
   "outputs": [],
   "source": [
    "def uni_bi(table,method):\n",
    "    uni = {'Prof':table[('Profitability')].describe(),\n",
    "            'EQ':table[('Earnings Quality')].describe(),\n",
    "            'Value':table[('Value')].describe(),\n",
    "            'Management Capability':table[('Management Capability')].describe(),\n",
    "            'Momentum':table[('Momentum')].describe()}\n",
    "\n",
    "    bi_inter = {'Prof':table[('Profitability')].corr(method),\n",
    "            'EQ':table[('Earnings Quality')].corr(method),\n",
    "            'Value':table[('Value')].corr(method),\n",
    "            'Management Capability':table[('Management Capability')].corr(method),\n",
    "            'Momentum':table[('Momentum')].corr(method)}\n",
    "\n",
    "    bi_forward ={\n",
    "            '1m':pd.concat([table[('Profitability')].corrwith(table[('Forward Returns','1m')],method=method),\n",
    "                    table[('Earnings Quality')].corrwith(table[('Forward Returns','1m')],method=method),\n",
    "                    table[('Value')].corrwith(table[('Forward Returns','1m')],method=method),\n",
    "                    table[('Management Capability')].corrwith(table[('Forward Returns','1m')],method=method),\n",
    "                    table[('Momentum')].corrwith(table[('Forward Returns','1m')],method=method)],axis=0),\n",
    "\n",
    "            '3m':pd.concat([table[('Profitability')].corrwith(table[('Forward Returns','3m')],method=method),\n",
    "                    table[('Earnings Quality')].corrwith(table[('Forward Returns','3m')],method=method),\n",
    "                    table[('Value')].corrwith(table[('Forward Returns','3m')],method=method),\n",
    "                    table[('Management Capability')].corrwith(table[('Forward Returns','3m')],method=method),\n",
    "                    table[('Momentum')].corrwith(table[('Forward Returns','3m')],method=method)],axis=0),\n",
    "            \n",
    "            '6m':pd.concat([table[('Profitability')].corrwith(table[('Forward Returns','6m')],method=method),\n",
    "                    table[('Earnings Quality')].corrwith(table[('Forward Returns','6m')],method=method),\n",
    "                    table[('Value')].corrwith(table[('Forward Returns','6m')],method=method),\n",
    "                    table[('Management Capability')].corrwith(table[('Forward Returns','6m')],method=method),\n",
    "                    table[('Momentum')].corrwith(table[('Forward Returns','6m')],method=method)],axis=0),\n",
    "            \n",
    "            '9m':pd.concat([table[('Profitability')].corrwith(table[('Forward Returns','9m')],method=method),\n",
    "                    table[('Earnings Quality')].corrwith(table[('Forward Returns','9m')],method=method),\n",
    "                    table[('Value')].corrwith(table[('Forward Returns','9m')],method=method),\n",
    "                    table[('Management Capability')].corrwith(table[('Forward Returns','9m')],method=method),\n",
    "                    table[('Momentum')].corrwith(table[('Forward Returns','9m')],method=method)],axis=0),\n",
    "            \n",
    "            '12m':pd.concat([table[('Profitability')].corrwith(table[('Forward Returns','12m')],method=method),\n",
    "                    table[('Earnings Quality')].corrwith(table[('Forward Returns','12m')],method=method),\n",
    "                    table[('Value')].corrwith(table[('Forward Returns','12m')],method=method),\n",
    "                    table[('Management Capability')].corrwith(table[('Forward Returns','12m')],method=method),\n",
    "                    table[('Momentum')].corrwith(table[('Forward Returns','12m')],method=method)],axis=0)}\n",
    "    return uni,bi_inter,bi_forward\n",
    "\n",
    "def ols_summar(theme,return_interval):\n",
    "    return sm.OLS(df[('Forward Returns',return_interval)],sm.add_constant(df[(theme)]),missing='drop').fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 565,
   "metadata": {},
   "outputs": [],
   "source": [
    "uni,bi_inter_pear,bi_forward_pear = uni_bi(df,'pearson')\n",
    "for theme,data in bi_forward_pear.items():\n",
    "    bi_forward_pear[theme]#.to_csv('Project Tables/'+'corr_forward'+theme+'.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 567,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                  0         1         2         3         4\n",
       "RoE       -0.038055 -0.047321 -0.010869  0.004903  0.003946\n",
       "CFO2A     -0.046498 -0.039890 -0.009737 -0.014757 -0.027934\n",
       "EPSg       0.014503 -0.011312 -0.008412  0.004571 -0.004760\n",
       "EBITDA/EV -0.019428 -0.043854 -0.025272 -0.025265 -0.018834\n",
       "Accruals   0.018140  0.016215 -0.005730 -0.006044  0.002719\n",
       "CFOg      -0.045125 -0.050032 -0.039245 -0.032498 -0.017827\n",
       "B/P       -0.036461 -0.012972 -0.014386 -0.018311 -0.027449\n",
       "E/P        0.015056 -0.073790 -0.041626 -0.050598 -0.034627\n",
       "CFO/P     -0.010893 -0.026337 -0.009639 -0.009329 -0.013404\n",
       "exFINg     0.015772 -0.028612 -0.044771 -0.030386  0.008339\n",
       "CapXg      0.011051 -0.007985  0.006117 -0.006239 -0.014233\n",
       "P3m        0.000231 -0.045369 -0.062007 -0.073093 -0.012391\n",
       "P6m        0.010815 -0.060295 -0.074360 -0.030508  0.034570\n",
       "P9m       -0.026781 -0.085698 -0.041130  0.016977  0.075398\n",
       "P12m      -0.013411 -0.049383 -0.019441  0.035341  0.074266"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>RoE</th>\n      <td>-0.038055</td>\n      <td>-0.047321</td>\n      <td>-0.010869</td>\n      <td>0.004903</td>\n      <td>0.003946</td>\n    </tr>\n    <tr>\n      <th>CFO2A</th>\n      <td>-0.046498</td>\n      <td>-0.039890</td>\n      <td>-0.009737</td>\n      <td>-0.014757</td>\n      <td>-0.027934</td>\n    </tr>\n    <tr>\n      <th>EPSg</th>\n      <td>0.014503</td>\n      <td>-0.011312</td>\n      <td>-0.008412</td>\n      <td>0.004571</td>\n      <td>-0.004760</td>\n    </tr>\n    <tr>\n      <th>EBITDA/EV</th>\n      <td>-0.019428</td>\n      <td>-0.043854</td>\n      <td>-0.025272</td>\n      <td>-0.025265</td>\n      <td>-0.018834</td>\n    </tr>\n    <tr>\n      <th>Accruals</th>\n      <td>0.018140</td>\n      <td>0.016215</td>\n      <td>-0.005730</td>\n      <td>-0.006044</td>\n      <td>0.002719</td>\n    </tr>\n    <tr>\n      <th>CFOg</th>\n      <td>-0.045125</td>\n      <td>-0.050032</td>\n      <td>-0.039245</td>\n      <td>-0.032498</td>\n      <td>-0.017827</td>\n    </tr>\n    <tr>\n      <th>B/P</th>\n      <td>-0.036461</td>\n      <td>-0.012972</td>\n      <td>-0.014386</td>\n      <td>-0.018311</td>\n      <td>-0.027449</td>\n    </tr>\n    <tr>\n      <th>E/P</th>\n      <td>0.015056</td>\n      <td>-0.073790</td>\n      <td>-0.041626</td>\n      <td>-0.050598</td>\n      <td>-0.034627</td>\n    </tr>\n    <tr>\n      <th>CFO/P</th>\n      <td>-0.010893</td>\n      <td>-0.026337</td>\n      <td>-0.009639</td>\n      <td>-0.009329</td>\n      <td>-0.013404</td>\n    </tr>\n    <tr>\n      <th>exFINg</th>\n      <td>0.015772</td>\n      <td>-0.028612</td>\n      <td>-0.044771</td>\n      <td>-0.030386</td>\n      <td>0.008339</td>\n    </tr>\n    <tr>\n      <th>CapXg</th>\n      <td>0.011051</td>\n      <td>-0.007985</td>\n      <td>0.006117</td>\n      <td>-0.006239</td>\n      <td>-0.014233</td>\n    </tr>\n    <tr>\n      <th>P3m</th>\n      <td>0.000231</td>\n      <td>-0.045369</td>\n      <td>-0.062007</td>\n      <td>-0.073093</td>\n      <td>-0.012391</td>\n    </tr>\n    <tr>\n      <th>P6m</th>\n      <td>0.010815</td>\n      <td>-0.060295</td>\n      <td>-0.074360</td>\n      <td>-0.030508</td>\n      <td>0.034570</td>\n    </tr>\n    <tr>\n      <th>P9m</th>\n      <td>-0.026781</td>\n      <td>-0.085698</td>\n      <td>-0.041130</td>\n      <td>0.016977</td>\n      <td>0.075398</td>\n    </tr>\n    <tr>\n      <th>P12m</th>\n      <td>-0.013411</td>\n      <td>-0.049383</td>\n      <td>-0.019441</td>\n      <td>0.035341</td>\n      <td>0.074266</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 567
    }
   ],
   "source": [
    "pd.concat(bi_forward_pear.values(),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uni,bi_inter_rank,bi_forward_rank = uni_bi(df,'spearman')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 540,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([i for i in uni.values()],axis=1).to_csv('uni.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_data('DIS',apikey)['Ratios'].iloc[:5,:6].to_latex(buf='Yash_table/table1.txt')\n",
    "signals_table['Forward Returns'].iloc[5:10,:3].to_latex(buf='Yash_table/table2.txt')\n",
    "signals_table[['Profitability','Forward Returns']].iloc[:5,:6].to_latex(buf='Yash_table/tabel3.txt')\n",
    "uni['Prof'].to_latex(buf='Yash_table/table4.txt')\n",
    "for theme in bi_inter_pear.keys():\n",
    "    bi_inter_pear[theme].to_latex('Yash_table/Pearson_'+theme+'.txt')\n",
    "for theme in bi_inter_pear.keys():\n",
    "    bi_inter_rank[theme].to_latex('Yash_table/Rank'+theme+'.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 570,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat({'Pearson':pd.DataFrame(bi_forward_pear).round(3),'Spearman':pd.DataFrame(bi_forward_rank).round(3)},axis=1).to_csv('Project Tables/Forward_corr.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 547,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ols_tables(theme,upto):\n",
    "    return pd.concat({\n",
    "        '1m R2('+str(ols_summar(theme,'1m').rsquared.round(upto))+')':\n",
    "        pd.DataFrame({'coef':ols_summar(theme,'1m').params.round(upto),\n",
    "                        't':ols_summar(theme,'1m').tvalues.round(upto),\n",
    "                        'p':ols_summar(theme,'1m').pvalues.round(upto)}),\n",
    "\n",
    "'3m R2('+str(ols_summar(theme,'3m').rsquared.round(upto))+')':\n",
    "pd.DataFrame({'coef':ols_summar(theme,'3m').params.round(upto),\n",
    "                't':ols_summar(theme,'3m').tvalues.round(upto),\n",
    "                'p':ols_summar(theme,'3m').pvalues.round(upto)}),\n",
    "\n",
    "'6m R2('+str(ols_summar(theme,'6m').rsquared.round(upto))+')':\n",
    "pd.DataFrame({'coef':ols_summar(theme,'6m').params.round(upto),\n",
    "                't':ols_summar(theme,'6m').tvalues.round(upto),\n",
    "                'p':ols_summar(theme,'6m').pvalues.round(upto)}),\n",
    "\n",
    "'9m R2('+str(ols_summar(theme,'9m').rsquared.round(upto))+')':\n",
    "pd.DataFrame({'coef':ols_summar(theme,'9m').params.round(upto),\n",
    "                't':ols_summar(theme,'9m').tvalues.round(upto),\n",
    "                'p':ols_summar(theme,'9m').pvalues.round(upto)})},axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 560,
   "metadata": {},
   "outputs": [],
   "source": [
    "themes = ['Profitability','Earnings Quality','Value','Momentum','Management Capability']\n",
    "ols_ = []\n",
    "for theme in themes:\n",
    "    ols_tables(theme,3).to_csv('Project Tables/'+theme+'.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 558,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[          1m R2(0.004)               3m R2(0.005)               6m R2(0.001)  \\\n",
       "                   coef      t      p         coef      t      p         coef   \n",
       " const           -0.000 -0.116  0.907       -0.001 -0.187  0.852       -0.015   \n",
       " RoE             -0.003 -1.386  0.166       -0.006 -1.654  0.098       -0.002   \n",
       " CFO2A           -0.125 -1.579  0.115       -0.136 -0.933  0.351        0.001   \n",
       " EPSg             0.000  0.551  0.582       -0.000 -0.375  0.708       -0.000   \n",
       " EBITDA/EV        0.006  0.046  0.964       -0.237 -0.992  0.322       -0.307   \n",
       " \n",
       "                         9m R2(0.001)                \n",
       "                t      p         coef      t      p  \n",
       " const     -1.314  0.189       -0.019 -1.243  0.214  \n",
       " RoE       -0.339  0.734        0.002  0.231  0.817  \n",
       " CFO2A      0.005  0.996       -0.057 -0.182  0.856  \n",
       " EPSg      -0.287  0.774        0.000  0.188  0.851  \n",
       " EBITDA/EV -0.818  0.413       -0.403 -0.786  0.432  ,\n",
       "          1m R2(0.002)               3m R2(0.003)               6m R2(0.002)  \\\n",
       "                  coef      t      p         coef      t      p         coef   \n",
       " const          -0.002 -0.756  0.450       -0.007 -1.154  0.249       -0.019   \n",
       " Accruals        0.048  0.611  0.541        0.077  0.535  0.592       -0.057   \n",
       " CFOg           -0.000 -1.624  0.105       -0.001 -1.806  0.071       -0.001   \n",
       " \n",
       "                        9m R2(0.001)                \n",
       "               t      p         coef      t      p  \n",
       " const    -2.039  0.042       -0.026 -2.084  0.037  \n",
       " Accruals -0.252  0.801       -0.079 -0.256  0.798  \n",
       " CFOg     -1.436  0.151       -0.001 -1.190  0.234  ,\n",
       "       1m R2(0.002)               3m R2(0.006)               6m R2(0.002)  \\\n",
       "               coef      t      p         coef      t      p         coef   \n",
       " const        0.002  0.318  0.751       -0.002 -0.215  0.830       -0.011   \n",
       " B/P         -0.019 -1.190  0.234       -0.013 -0.436  0.663       -0.029   \n",
       " E/P          0.060  0.575  0.565       -0.492 -2.549  0.011       -0.469   \n",
       " CFO/P       -0.016 -0.108  0.914        0.037  0.132  0.895        0.178   \n",
       " \n",
       "                     9m R2(0.003)                \n",
       "            t      p         coef      t      p  \n",
       " const -0.699  0.484       -0.012 -0.558  0.577  \n",
       " B/P   -0.611  0.541       -0.052 -0.815  0.415  \n",
       " E/P   -1.549  0.122       -0.797 -1.925  0.055  \n",
       " CFO/P  0.403  0.687        0.364  0.604  0.546  ,\n",
       "       1m R2(0.004)               3m R2(0.011)               6m R2(0.008)  \\\n",
       "               coef      t      p         coef      t      p         coef   \n",
       " const       -0.004 -0.232  0.816        0.043  1.399  0.162        0.091   \n",
       " P3m         -0.009 -0.444  0.657       -0.013 -0.331  0.741       -0.031   \n",
       " P6m          0.039  1.969  0.049        0.025  0.702  0.483       -0.107   \n",
       " P9m         -0.040 -2.102  0.036       -0.108 -3.114  0.002       -0.012   \n",
       " P12m         0.011  0.895  0.371        0.047  2.127  0.034        0.043   \n",
       " \n",
       "                     9m R2(0.012)                \n",
       "            t      p         coef      t      p  \n",
       " const  1.890  0.059        0.152  2.306  0.021  \n",
       " P3m   -0.515  0.606       -0.202 -2.423  0.016  \n",
       " P6m   -1.885  0.060       -0.083 -1.075  0.282  \n",
       " P9m   -0.216  0.829        0.034  0.465  0.642  \n",
       " P12m   1.226  0.220        0.068  1.437  0.151  ,\n",
       "        1m R2(0.0)               3m R2(0.001)               6m R2(0.002)  \\\n",
       "              coef      t      p         coef      t      p         coef   \n",
       " const      -0.010 -0.870  0.384        0.012  0.558  0.577        0.033   \n",
       " exFINg      0.006  0.549  0.583       -0.021 -1.025  0.306       -0.052   \n",
       " CapXg       0.000  0.365  0.715       -0.000 -0.222  0.824        0.000   \n",
       " \n",
       "                      9m R2(0.001)                \n",
       "             t      p         coef      t      p  \n",
       " const   0.978  0.328        0.021  0.455  0.649  \n",
       " exFINg -1.649  0.099       -0.047 -1.094  0.274  \n",
       " CapXg   0.332  0.740       -0.000 -0.154  0.877  ]"
      ]
     },
     "metadata": {},
     "execution_count": 558
    }
   ],
   "source": [
    "ols_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\\begin{center}\n\\begin{tabular}{lclc}\n\\toprule\n\\textbf{Dep. Variable:}    & ('Forward Returns', '9m') & \\textbf{  R-squared:         } &     0.051   \\\\\n\\textbf{Model:}            &            OLS            & \\textbf{  Adj. R-squared:    } &     0.039   \\\\\n\\textbf{Method:}           &       Least Squares       & \\textbf{  F-statistic:       } &     4.190   \\\\\n\\textbf{Date:}             &      Sun, 01 Nov 2020     & \\textbf{  Prob (F-statistic):} &   0.0169    \\\\\n\\textbf{Time:}             &          18:35:55         & \\textbf{  Log-Likelihood:    } &   -27.155   \\\\\n\\textbf{No. Observations:} &              160          & \\textbf{  AIC:               } &     60.31   \\\\\n\\textbf{Df Residuals:}     &              157          & \\textbf{  BIC:               } &     69.53   \\\\\n\\textbf{Df Model:}         &                2          & \\textbf{                     } &             \\\\\n\\bottomrule\n\\end{tabular}\n\\begin{tabular}{lcccccc}\n                  & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n\\midrule\n\\textbf{const}    &      -0.0385  &        0.025     &    -1.509  &         0.133        &       -0.089    &        0.012     \\\\\n\\textbf{Accruals} &      -5.9565  &        2.409     &    -2.472  &         0.014        &      -10.715    &       -1.198     \\\\\n\\textbf{CFOg}     &       0.0020  &        0.002     &     1.033  &         0.303        &       -0.002    &        0.006     \\\\\n\\bottomrule\n\\end{tabular}\n\\begin{tabular}{lclc}\n\\textbf{Omnibus:}       & 89.285 & \\textbf{  Durbin-Watson:     } &     0.715  \\\\\n\\textbf{Prob(Omnibus):} &  0.000 & \\textbf{  Jarque-Bera (JB):  } &   477.161  \\\\\n\\textbf{Skew:}          &  2.046 & \\textbf{  Prob(JB):          } & 2.43e-104  \\\\\n\\textbf{Kurtosis:}      & 10.405 & \\textbf{  Cond. No.          } &  1.31e+03  \\\\\n\\bottomrule\n\\end{tabular}\n%\\caption{OLS Regression Results}\n\\end{center}\n\nNotes: \\newline\n [1] Standard Errors assume that the covariance matrix of the errors is correctly specified. \\newline\n [2] The condition number is large, 1.31e+03. This might indicate that there are \\newline\n strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "print(ols_summar('Earnings Quality','9m').summary().as_latex())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}